#!/usr/bin/env python
"""
Convert GPT-generated reasoning answers to Qwen3-VL SFT training format.

This script takes the JSON files generated by vanilla_grounding_reasoning_dataset_generation.py
and converts them to the JSONL format required for Qwen3-VL SFT training.

Input format (from GPT generation):
{
    "index": 0,
    "question": "lady with the blue shirt",
    "image_path": "coco_flip/train2014/COCO_train2014_000000581857.jpg",
    "gt_bbox_normalized": [444, 468, 757, 745],  # 0-999 normalized
    "gt_bbox_absolute": [444, 468, 757, 745],    # pixel coordinates
    "image_height": 640,
    "image_width": 427,
    "gpt_analysis": "To correctly output the bounding box..."
}

Output format (Qwen3-VL SFT):
{
    "id": -1,
    "image": "coco_flip/train2014/COCO_train2014_000000581857.jpg",
    "height": 640,
    "width": 427,
    "conversations": [
        {
            "from": "human", 
            "value": "<image>\nLocate lady with the blue shirt, output its bbox coordinates using JSON format."
        },
        {
            "from": "gpt",
            "value": "To correctly output the bounding box...\n</think>\n\n```json\n[\n\t{\"bbox_2d\": [444, 468, 757, 745], \"label\": \"lady with the blue shirt\"}\n]\n```"
        }
    ]
}
"""

import os
import json
import glob
import argparse
from tqdm import tqdm
from typing import List, Dict, Optional


def load_gpt_json_files(gpt_answer_dir: str) -> List[Dict]:
    """Load all GPT analysis JSON files from the directory."""
    json_files = sorted(glob.glob(os.path.join(gpt_answer_dir, "analysis_*.json")))
    
    data = []
    for json_path in tqdm(json_files, desc="Loading GPT JSON files"):
        try:
            with open(json_path, 'r', encoding='utf-8') as f:
                item = json.load(f)
                data.append(item)
        except Exception as e:
            print(f"Warning: Failed to load {json_path}: {e}")
    
    return data


def convert_to_qwen3_format(item: Dict) -> Optional[Dict]:
    """Convert a single GPT analysis item to Qwen3-VL SFT format."""
    try:
        question = item['question']
        image_path = item['image_path']
        height = item['image_height']
        width = item['image_width']
        gpt_analysis = item['gpt_analysis']
        
        # Use normalized bbox coordinates (0-999)
        bbox = item['gt_bbox_normalized']
        
        # Construct human question
        human_value = f"<image>\nLocate {question}, output its bbox coordinates using JSON format."
        
        # Construct GPT answer with reasoning and bbox
        # Format: reasoning + </think> + JSON bbox
        gpt_value = f"{gpt_analysis}\n</think>\n\n```json\n[\n\t{{\"bbox_2d\": {bbox}, \"label\": \"{question}\"}}\n]\n```"
        
        result = {
            "id": -1,
            "image": image_path,
            "height": height,
            "width": width,
            "conversations": [
                {
                    "from": "human",
                    "value": human_value
                },
                {
                    "from": "gpt",
                    "value": gpt_value
                }
            ]
        }
        
        return result
        
    except KeyError as e:
        print(f"Warning: Missing key {e} in item with index {item.get('index', 'unknown')}")
        return None
    except Exception as e:
        print(f"Warning: Failed to convert item with index {item.get('index', 'unknown')}: {e}")
        return None


def main():
    parser = argparse.ArgumentParser(
        description='Convert GPT-generated reasoning to Qwen3-VL SFT training format',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Example usage:
    python convert_gpt_to_qwen3_sft.py \\
        --gpt_answer_dir ./gpt_answers \\
        --output_jsonl ./qwen3_sft_train.jsonl
        """
    )
    parser.add_argument(
        '--gpt_answer_dir',
        type=str,
        required=True,
        help='Directory containing GPT analysis JSON files (from vanilla_grounding_reasoning_dataset_generation.py)'
    )
    parser.add_argument(
        '--output_jsonl',
        type=str,
        required=True,
        help='Output JSONL file path for Qwen3-VL SFT training'
    )
    
    args = parser.parse_args()
    
    # Check input directory exists
    if not os.path.exists(args.gpt_answer_dir):
        print(f"Error: GPT answer directory not found: {args.gpt_answer_dir}")
        return
    
    # Load GPT analysis files
    print(f"Loading GPT analysis files from: {args.gpt_answer_dir}")
    gpt_data = load_gpt_json_files(args.gpt_answer_dir)
    print(f"Loaded {len(gpt_data)} GPT analysis files")
    
    if len(gpt_data) == 0:
        print("Error: No GPT analysis files found!")
        return
    
    # Convert to Qwen3-VL format
    print("Converting to Qwen3-VL SFT format...")
    converted_data = []
    failed_count = 0
    
    for item in tqdm(gpt_data, desc="Converting"):
        result = convert_to_qwen3_format(item)
        if result is not None:
            converted_data.append(result)
        else:
            failed_count += 1
    
    # Create output directory if needed
    output_dir = os.path.dirname(args.output_jsonl)
    if output_dir and not os.path.exists(output_dir):
        os.makedirs(output_dir, exist_ok=True)
    
    # Write output JSONL
    print(f"Writing output to: {args.output_jsonl}")
    with open(args.output_jsonl, 'w', encoding='utf-8') as f:
        for item in converted_data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')
    
    # Summary
    print(f"\n{'='*60}")
    print(f"Conversion completed!")
    print(f"{'='*60}")
    print(f"‚úÖ Successfully converted: {len(converted_data)}")
    print(f"‚ùå Failed: {failed_count}")
    print(f"üìÑ Output file: {args.output_jsonl}")
    print(f"üìä Total samples: {len(converted_data)}")


if __name__ == "__main__":
    main()
